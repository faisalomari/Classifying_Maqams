{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MaqamCNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaqamCNN1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=30, out_channels=64, kernel_size=(3,3), padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,1))\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1,1), padding=\"valid\")\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1,1))\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc1 = nn.Linear(30016, 512)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 265)\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(265, 100)\n",
    "        self.dropout5 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=30, out_channels=64, kernel_size=(3,3), padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(1,1))\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(1,1), padding=\"valid\")\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(1,1))\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, batch_first=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.25)\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout4 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.dropout5 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Reshape the CNN output to match LSTM input\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, channels, height * width)\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, sequence_length, input_size)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        x = self.fc1(x[:, -1, :])\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = self.dropout4(x)\n",
    "\n",
    "        # x = self.fc3(x)\n",
    "        # x = self.dropout5(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MFCC_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MFCC_LSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=30, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(x.shape)\n",
    "        _, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        x = hn[-1]  # Take the last hidden state of the LSTM\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MaqamDataset(Dataset):\n",
    "    def __init__(self, mode='train', transform=None, cache_file='1.pkl', test_size=0.2):\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        if mode == 'train' or mode == 'val':\n",
    "            self.data_dir = \"/home/faisal/Desktop/MAQAMAT/Fullynewdataset\"\n",
    "        else:\n",
    "            self.data_dir = \"/home/faisal/Desktop/MAQAMAT/Test1\"\n",
    "        #['Ajam', 'Bayat', 'Hijaz', 'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "        self.maqams = ['Ajam', 'Bayat', 'Hijaz', 'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "        self.audio_list = self._load_audio_list()\n",
    "        \n",
    "        # Split the dataset into training and validation sets using train_test_split method\n",
    "        if(self.mode == 'train'):\n",
    "            train_list, val_list = train_test_split(self.audio_list, test_size=test_size, random_state=42, stratify=[label for (_, label) in self.audio_list])\n",
    "            self.audio_list = train_list\n",
    "        elif(self.mode == 'val'):\n",
    "            train_list, val_list = train_test_split(self.audio_list, test_size=test_size, random_state=42, stratify=[label for (_, label) in self.audio_list])\n",
    "            self.audio_list = val_list\n",
    "        \n",
    "        self.cache_file = cache_file\n",
    "        self.data = self._load_data_from_cache_or_compute()\n",
    "        # self.pad_to_max_length(1440000)\n",
    "\n",
    "    def _load_audio_list(self):\n",
    "        audio_list = []\n",
    "        for i, maqam in enumerate(self.maqams):\n",
    "            label_dir = os.path.join(self.data_dir, maqam)\n",
    "            audio_list += [(os.path.join(label_dir, audio_name), i) for audio_name in os.listdir(label_dir) if audio_name.endswith('.wav')]\n",
    "        return audio_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, label_idx = self.audio_list[idx]\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        waveform = waveform[0] # only keep the first channel\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        mfcc = self.compute_mfcc(waveform).T\n",
    "        mfcc = torch.from_numpy(mfcc).float()\n",
    "        return mfcc, label_idx\n",
    "    \n",
    "    def pad_to_max_length(self, max_length):\n",
    "        for i in range(len(self)):\n",
    "            padded_data = F.pad(self.data[i][0], (0, max_length - len(self.data[i][0])), 'constant', 0)\n",
    "            self.data[i] = (padded_data, self.data[i][1])\n",
    "\n",
    "    def compute_mfcc(self, waveform):\n",
    "        # Compute the MFCC of the waveform\n",
    "        n_fft = 1024*8\n",
    "        hop_length = 512*2\n",
    "        n_mels = 100\n",
    "        sr = 16000\n",
    "        n_mfcc = 30\n",
    "        waveform = waveform.numpy()  # Convert PyTorch tensor to NumPy array\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, n_mfcc=n_mfcc)\n",
    "        mfcc = np.transpose(mfcc)\n",
    "        mfcc = mfcc.astype(np.float32)  # Ensure data type is compatible with np.issubdtype()\n",
    "        return mfcc\n",
    "    \n",
    "    def _load_data_from_cache_or_compute(self):\n",
    "        if os.path.isfile(self.cache_file):\n",
    "            print(f'Loading data from cache file: {self.cache_file}')\n",
    "            with open(self.cache_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            print(f'Cache file not found. Computing data from scratch and saving to cache file: {self.cache_file}')\n",
    "            data = [self.__getitem__(i) for i in range(len(self))]\n",
    "            with open(self.cache_file, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "max_length = 1440000\n",
    "\n",
    "def MFCC_plot(mfcc):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        mfcc = mfcc.detach().numpy()\n",
    "        mfcc = mfcc.mean(axis=2).T\n",
    "        librosa.display.specshow(mfcc, x_axis='time')\n",
    "        plt.colorbar()\n",
    "        plt.title('MFCC')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def custom_collate(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    max_frames = max([m.shape[1] for m in inputs])\n",
    "    padded_mfcc = []\n",
    "    for m in inputs:\n",
    "        pad_width = ((0, 0), (0, max_frames - m.shape[1]))\n",
    "        padded_m = np.pad(m, pad_width=pad_width, mode='constant')\n",
    "        padded_mfcc.append(padded_m)\n",
    "\n",
    "    padded_mfcc = torch.from_numpy(np.array(padded_mfcc)).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    return padded_mfcc, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from cache file: 1.pkl\n",
      "Loading data from cache file: 1.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with specified test size\n",
    "train_dataset = MaqamDataset(mode='train', test_size=0.2)\n",
    "val_dataset = MaqamDataset(mode='val', test_size=0.2)\n",
    "\n",
    "# Define training and validation data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.init()\n",
    "torch.cuda.empty_cache()\n",
    "option = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: Train Loss=2.07732, Train Accuracy=15.88694%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 validation: val_loss=2.07291, val_acc=24.51362%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: Train Loss=2.06725, Train Accuracy=24.85380%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 validation: val_loss=2.06316, val_acc=26.07004%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: Train Loss=2.04549, Train Accuracy=26.02339%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 validation: val_loss=2.03862, val_acc=25.68093%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if(option == 1):\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.empty_cache()\n",
    "    # Initialize model and define loss function and optimizer\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = MFCC_LSTM().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Train the model for a specified number of epochs\n",
    "    num_epochs = 3\n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode for the current epoch\n",
    "        model.train()\n",
    "\n",
    "        # Create a progress bar for the train_loader loop\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "\n",
    "        # Initialize variables to track the loss and number of correct predictions\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, data in enumerate(train_loader_tqdm):\n",
    "            inputs, targets = data  # MFCCs and labels\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the loss and accuracy metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "\n",
    "            # Update the progress bar description\n",
    "            train_loader_tqdm.set_postfix({'Loss': running_loss / (i + 1), 'Accuracy': 100 * correct_predictions / total_samples})\n",
    "\n",
    "        # Calculate and print average loss and accuracy for the current epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = 100 * correct_predictions / total_samples\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss={avg_loss:.5f}, Train Accuracy={avg_accuracy:.5f}%')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Create a progress bar for the val_loader loop\n",
    "            val_loader_tqdm = tqdm(val_loader, desc='Validation', leave=False)\n",
    "\n",
    "            for data in val_loader_tqdm:\n",
    "                inputs, targets = data  # MFCCs and labels\n",
    "                targets = targets.to(device)\n",
    "                inputs = inputs.cuda()\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * len(targets)\n",
    "\n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                total_correct += (predicted_labels == targets).sum().item()\n",
    "                total_samples += len(targets)\n",
    "\n",
    "                # Update the progress bar description\n",
    "                val_loader_tqdm.set_postfix({'Validation Loss': val_loss / total_samples, 'Validation Accuracy': 100 * total_correct / total_samples})\n",
    "\n",
    "            val_loss /= len(val_dataset)\n",
    "            val_acc = float(total_correct) / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} validation: val_loss={val_loss:.5f}, val_acc={100*val_acc:.5f}%')\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'readerstest.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from cache file: 1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24980/3981001201.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs_tensor = torch.tensor(outputs[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_labels:  tensor([[0.2298, 0.0701, 0.2310, 0.1162, 0.1376, 0.0751, 0.0602, 0.0800],\n",
      "        [0.1671, 0.0871, 0.2256, 0.1062, 0.1463, 0.1190, 0.0577, 0.0909],\n",
      "        [0.1489, 0.1055, 0.1119, 0.0722, 0.1947, 0.1663, 0.1238, 0.0766],\n",
      "        [0.1596, 0.0803, 0.2251, 0.0985, 0.1288, 0.0986, 0.0724, 0.1366],\n",
      "        [0.1604, 0.0678, 0.1455, 0.0828, 0.1432, 0.1724, 0.0783, 0.1496],\n",
      "        [0.1798, 0.0932, 0.2903, 0.1504, 0.0754, 0.0601, 0.0465, 0.1043],\n",
      "        [0.1824, 0.0720, 0.3236, 0.1259, 0.0886, 0.0650, 0.0573, 0.0851],\n",
      "        [0.1514, 0.0878, 0.3118, 0.1368, 0.0976, 0.0780, 0.0634, 0.0734],\n",
      "        [0.2378, 0.0910, 0.1193, 0.0611, 0.1376, 0.1977, 0.0798, 0.0758],\n",
      "        [0.1969, 0.0546, 0.1749, 0.0919, 0.1412, 0.0806, 0.1152, 0.1447],\n",
      "        [0.1485, 0.1038, 0.1681, 0.0930, 0.1204, 0.1962, 0.0550, 0.1150],\n",
      "        [0.1769, 0.0920, 0.2795, 0.1567, 0.0808, 0.0809, 0.0379, 0.0953],\n",
      "        [0.1542, 0.0611, 0.2042, 0.0686, 0.1589, 0.0604, 0.2260, 0.0665],\n",
      "        [0.1566, 0.0650, 0.2166, 0.0945, 0.1267, 0.1031, 0.0573, 0.1802],\n",
      "        [0.2300, 0.0583, 0.1756, 0.0700, 0.1298, 0.1329, 0.0710, 0.1324],\n",
      "        [0.2329, 0.0817, 0.1798, 0.1124, 0.1650, 0.0987, 0.0569, 0.0727],\n",
      "        [0.1897, 0.0929, 0.1471, 0.0696, 0.2055, 0.0885, 0.1284, 0.0783],\n",
      "        [0.1749, 0.0914, 0.1636, 0.0968, 0.1282, 0.1362, 0.0906, 0.1184],\n",
      "        [0.1713, 0.0971, 0.2652, 0.1267, 0.0871, 0.1087, 0.0309, 0.1130],\n",
      "        [0.1548, 0.0673, 0.3182, 0.1264, 0.0941, 0.0748, 0.0551, 0.1094],\n",
      "        [0.1933, 0.0686, 0.2259, 0.0894, 0.1196, 0.1170, 0.0417, 0.1446],\n",
      "        [0.2053, 0.0744, 0.1182, 0.0639, 0.1719, 0.1498, 0.1441, 0.0724],\n",
      "        [0.1795, 0.0883, 0.2310, 0.1301, 0.1108, 0.1089, 0.0367, 0.1146],\n",
      "        [0.1774, 0.0810, 0.1683, 0.0927, 0.1109, 0.1591, 0.0512, 0.1595],\n",
      "        [0.1990, 0.1167, 0.1407, 0.0836, 0.1606, 0.1509, 0.0689, 0.0795],\n",
      "        [0.1702, 0.0724, 0.2259, 0.0739, 0.1336, 0.0568, 0.1902, 0.0771],\n",
      "        [0.1911, 0.0612, 0.2151, 0.1001, 0.1054, 0.1276, 0.0446, 0.1548],\n",
      "        [0.1654, 0.0673, 0.2455, 0.1353, 0.0989, 0.0828, 0.0637, 0.1411],\n",
      "        [0.1535, 0.0707, 0.2994, 0.1334, 0.1054, 0.0673, 0.0511, 0.1192],\n",
      "        [0.2219, 0.0770, 0.1571, 0.0579, 0.1548, 0.0954, 0.1668, 0.0690],\n",
      "        [0.1821, 0.0656, 0.3047, 0.1241, 0.0935, 0.0739, 0.0598, 0.0962],\n",
      "        [0.1407, 0.0845, 0.3339, 0.1360, 0.0952, 0.0775, 0.0530, 0.0792]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1991, 0.0672, 0.0821, 0.0425, 0.1920, 0.1533, 0.1792, 0.0846],\n",
      "        [0.2299, 0.0684, 0.1711, 0.0833, 0.1375, 0.1243, 0.0896, 0.0960],\n",
      "        [0.1950, 0.0835, 0.2279, 0.1221, 0.1354, 0.0717, 0.0722, 0.0921],\n",
      "        [0.1193, 0.1341, 0.1011, 0.0556, 0.1815, 0.1297, 0.2125, 0.0662],\n",
      "        [0.1682, 0.0730, 0.3037, 0.1022, 0.1005, 0.0652, 0.1202, 0.0670],\n",
      "        [0.1506, 0.0865, 0.3114, 0.1173, 0.0770, 0.0743, 0.0479, 0.1350],\n",
      "        [0.1484, 0.0832, 0.3694, 0.1507, 0.0647, 0.0481, 0.0536, 0.0818],\n",
      "        [0.1275, 0.0972, 0.2637, 0.1235, 0.1030, 0.1068, 0.0873, 0.0910],\n",
      "        [0.1756, 0.0922, 0.2700, 0.1075, 0.0984, 0.0735, 0.1044, 0.0784],\n",
      "        [0.1511, 0.0653, 0.1785, 0.0595, 0.1749, 0.0654, 0.2197, 0.0856],\n",
      "        [0.1833, 0.0766, 0.2631, 0.0917, 0.1032, 0.0576, 0.1200, 0.1044],\n",
      "        [0.1400, 0.0927, 0.2336, 0.1016, 0.1195, 0.1004, 0.1100, 0.1023],\n",
      "        [0.1456, 0.0570, 0.1863, 0.0606, 0.1694, 0.0597, 0.2710, 0.0504],\n",
      "        [0.1460, 0.1149, 0.0645, 0.0399, 0.1926, 0.1184, 0.2603, 0.0634],\n",
      "        [0.1356, 0.1043, 0.1436, 0.0931, 0.1228, 0.0843, 0.2159, 0.1004],\n",
      "        [0.1416, 0.0965, 0.1759, 0.0644, 0.1638, 0.0874, 0.2006, 0.0699],\n",
      "        [0.1987, 0.0915, 0.1330, 0.0772, 0.1651, 0.1440, 0.1020, 0.0885],\n",
      "        [0.1774, 0.1042, 0.1616, 0.0992, 0.1495, 0.1594, 0.0788, 0.0699],\n",
      "        [0.1313, 0.0642, 0.1362, 0.0532, 0.2081, 0.0656, 0.2453, 0.0962],\n",
      "        [0.1642, 0.0867, 0.1900, 0.0895, 0.1598, 0.1080, 0.1028, 0.0991],\n",
      "        [0.1443, 0.0900, 0.3167, 0.1165, 0.1015, 0.0587, 0.0884, 0.0838],\n",
      "        [0.1587, 0.0777, 0.1693, 0.0746, 0.1848, 0.0792, 0.1611, 0.0946],\n",
      "        [0.1319, 0.1030, 0.0863, 0.0566, 0.1673, 0.1316, 0.2389, 0.0845],\n",
      "        [0.1400, 0.1244, 0.1290, 0.0896, 0.1618, 0.1403, 0.1220, 0.0928],\n",
      "        [0.1905, 0.0769, 0.2041, 0.0678, 0.1085, 0.0704, 0.1829, 0.0990],\n",
      "        [0.1306, 0.0717, 0.0993, 0.0409, 0.1631, 0.0837, 0.3551, 0.0556],\n",
      "        [0.1337, 0.0835, 0.1380, 0.0456, 0.1843, 0.0657, 0.3007, 0.0486],\n",
      "        [0.1534, 0.0507, 0.1849, 0.0673, 0.1756, 0.0762, 0.2160, 0.0759],\n",
      "        [0.1707, 0.0924, 0.3437, 0.1507, 0.0683, 0.0569, 0.0373, 0.0800],\n",
      "        [0.1599, 0.0683, 0.2118, 0.0873, 0.1340, 0.0801, 0.1136, 0.1450],\n",
      "        [0.1448, 0.0698, 0.1996, 0.0607, 0.1612, 0.0723, 0.2256, 0.0660],\n",
      "        [0.1421, 0.1143, 0.0938, 0.0497, 0.1733, 0.1120, 0.2474, 0.0675]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1914, 0.1024, 0.1460, 0.0819, 0.1416, 0.1729, 0.0625, 0.1015],\n",
      "        [0.1679, 0.0750, 0.2917, 0.0962, 0.1256, 0.0779, 0.1039, 0.0617],\n",
      "        [0.1384, 0.0729, 0.3499, 0.1409, 0.0881, 0.0697, 0.0611, 0.0790],\n",
      "        [0.1716, 0.0824, 0.1172, 0.0681, 0.1635, 0.1379, 0.1565, 0.1027],\n",
      "        [0.1728, 0.1065, 0.1431, 0.0612, 0.1611, 0.1108, 0.1734, 0.0711],\n",
      "        [0.1216, 0.0905, 0.3069, 0.1179, 0.0844, 0.1123, 0.0761, 0.0903],\n",
      "        [0.1533, 0.0748, 0.2967, 0.1307, 0.1139, 0.0812, 0.0540, 0.0953],\n",
      "        [0.1724, 0.0825, 0.2771, 0.1103, 0.0901, 0.0637, 0.0378, 0.1660],\n",
      "        [0.1265, 0.0867, 0.3388, 0.1593, 0.0779, 0.0689, 0.0503, 0.0917],\n",
      "        [0.1679, 0.0769, 0.1753, 0.0912, 0.1315, 0.0954, 0.0619, 0.1998],\n",
      "        [0.1900, 0.0755, 0.2056, 0.1002, 0.1315, 0.1268, 0.0461, 0.1242],\n",
      "        [0.1972, 0.0598, 0.2206, 0.0973, 0.1323, 0.0878, 0.0903, 0.1147],\n",
      "        [0.1206, 0.0930, 0.3473, 0.1503, 0.0817, 0.0723, 0.0515, 0.0832],\n",
      "        [0.1653, 0.0621, 0.1909, 0.1049, 0.1487, 0.0717, 0.1357, 0.1206],\n",
      "        [0.1937, 0.0746, 0.2468, 0.1148, 0.1211, 0.1147, 0.0491, 0.0852],\n",
      "        [0.1388, 0.0657, 0.1420, 0.0518, 0.1885, 0.0641, 0.2769, 0.0722],\n",
      "        [0.1188, 0.0582, 0.1330, 0.0405, 0.1900, 0.0502, 0.3700, 0.0393],\n",
      "        [0.1808, 0.0575, 0.2709, 0.1012, 0.1140, 0.0844, 0.0589, 0.1323],\n",
      "        [0.1777, 0.0869, 0.1281, 0.0715, 0.1646, 0.1239, 0.1304, 0.1169],\n",
      "        [0.1548, 0.0927, 0.2248, 0.1216, 0.1193, 0.0791, 0.1044, 0.1034],\n",
      "        [0.1420, 0.0887, 0.2678, 0.1221, 0.0938, 0.1157, 0.0449, 0.1251],\n",
      "        [0.1095, 0.0697, 0.1044, 0.0355, 0.1888, 0.0722, 0.3526, 0.0672],\n",
      "        [0.1903, 0.0740, 0.1571, 0.0801, 0.1424, 0.1469, 0.1103, 0.0991],\n",
      "        [0.1665, 0.0768, 0.3386, 0.1174, 0.0681, 0.0723, 0.0627, 0.0976],\n",
      "        [0.1936, 0.1004, 0.1684, 0.1137, 0.1660, 0.1092, 0.0708, 0.0779],\n",
      "        [0.1738, 0.0607, 0.2809, 0.1041, 0.1367, 0.0677, 0.0836, 0.0924],\n",
      "        [0.1450, 0.0683, 0.3320, 0.1528, 0.0696, 0.0527, 0.0421, 0.1374],\n",
      "        [0.1521, 0.0785, 0.3345, 0.1307, 0.0862, 0.0521, 0.0499, 0.1160],\n",
      "        [0.1794, 0.0691, 0.2300, 0.0867, 0.1439, 0.0916, 0.1211, 0.0782],\n",
      "        [0.1811, 0.0761, 0.2092, 0.0758, 0.1320, 0.0769, 0.1931, 0.0558],\n",
      "        [0.1580, 0.0823, 0.2714, 0.1028, 0.0911, 0.0826, 0.0459, 0.1658],\n",
      "        [0.1392, 0.0918, 0.2613, 0.1426, 0.0938, 0.0869, 0.0541, 0.1304]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1684, 0.0753, 0.3206, 0.1148, 0.0986, 0.0636, 0.0772, 0.0814],\n",
      "        [0.1499, 0.0845, 0.2818, 0.1287, 0.1132, 0.0845, 0.0647, 0.0927],\n",
      "        [0.1504, 0.1099, 0.2315, 0.1166, 0.1002, 0.1046, 0.0796, 0.1072],\n",
      "        [0.1715, 0.0887, 0.2271, 0.1150, 0.0958, 0.1420, 0.0465, 0.1133],\n",
      "        [0.1856, 0.0821, 0.2582, 0.1008, 0.0962, 0.0577, 0.1049, 0.1145],\n",
      "        [0.1554, 0.0503, 0.2099, 0.0711, 0.1590, 0.0742, 0.1952, 0.0848],\n",
      "        [0.1222, 0.0715, 0.1014, 0.0404, 0.1643, 0.0862, 0.3581, 0.0559],\n",
      "        [0.1370, 0.1185, 0.0945, 0.0523, 0.1712, 0.1124, 0.2466, 0.0675],\n",
      "        [0.1397, 0.0624, 0.1855, 0.0636, 0.1682, 0.0669, 0.2603, 0.0534],\n",
      "        [0.2009, 0.0987, 0.1448, 0.0794, 0.1429, 0.1638, 0.0676, 0.1019],\n",
      "        [0.1850, 0.0867, 0.1978, 0.0772, 0.1044, 0.0704, 0.1649, 0.1135],\n",
      "        [0.1654, 0.0897, 0.3489, 0.1505, 0.0667, 0.0546, 0.0363, 0.0879],\n",
      "        [0.1475, 0.1052, 0.1975, 0.0902, 0.1581, 0.0924, 0.1177, 0.0914],\n",
      "        [0.1425, 0.0925, 0.2858, 0.1044, 0.1160, 0.0599, 0.1187, 0.0803],\n",
      "        [0.1338, 0.1005, 0.0784, 0.0593, 0.1584, 0.1340, 0.2431, 0.0926],\n",
      "        [0.1772, 0.0820, 0.3008, 0.0953, 0.0962, 0.0663, 0.1106, 0.0716],\n",
      "        [0.1657, 0.0774, 0.2779, 0.0995, 0.1044, 0.0677, 0.1369, 0.0705],\n",
      "        [0.1560, 0.0836, 0.3646, 0.1483, 0.0660, 0.0485, 0.0570, 0.0761],\n",
      "        [0.1924, 0.1035, 0.1568, 0.0975, 0.1383, 0.1669, 0.0695, 0.0751],\n",
      "        [0.1203, 0.1349, 0.1024, 0.0575, 0.1748, 0.1337, 0.2072, 0.0691],\n",
      "        [0.1552, 0.0716, 0.1823, 0.0850, 0.1319, 0.0903, 0.1231, 0.1607],\n",
      "        [0.1377, 0.1074, 0.2018, 0.0956, 0.1235, 0.1405, 0.0968, 0.0968],\n",
      "        [0.1798, 0.0828, 0.2022, 0.0897, 0.1553, 0.0980, 0.1001, 0.0920],\n",
      "        [0.1474, 0.1082, 0.0627, 0.0371, 0.1925, 0.1140, 0.2747, 0.0635],\n",
      "        [0.2024, 0.0847, 0.1247, 0.0716, 0.1759, 0.1493, 0.1045, 0.0870],\n",
      "        [0.1265, 0.0570, 0.1525, 0.0576, 0.1994, 0.0705, 0.2200, 0.1165],\n",
      "        [0.1330, 0.0980, 0.3036, 0.1314, 0.0795, 0.0780, 0.0556, 0.1208],\n",
      "        [0.1378, 0.1157, 0.1444, 0.1004, 0.1188, 0.0892, 0.1981, 0.0955],\n",
      "        [0.1748, 0.0745, 0.1856, 0.0788, 0.1741, 0.0704, 0.1408, 0.1009],\n",
      "        [0.1629, 0.0643, 0.2038, 0.0682, 0.1704, 0.0660, 0.1796, 0.0847],\n",
      "        [0.1307, 0.1172, 0.1256, 0.0847, 0.1611, 0.1512, 0.1336, 0.0959],\n",
      "        [0.1607, 0.0942, 0.1727, 0.0722, 0.1758, 0.0996, 0.1145, 0.1103]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1600, 0.0623, 0.1416, 0.0624, 0.2018, 0.0774, 0.2090, 0.0856],\n",
      "        [0.1961, 0.1047, 0.1038, 0.0669, 0.1710, 0.1730, 0.1206, 0.0639],\n",
      "        [0.1493, 0.1197, 0.0723, 0.0593, 0.2098, 0.2110, 0.1179, 0.0606],\n",
      "        [0.1293, 0.0801, 0.1508, 0.0574, 0.1572, 0.0584, 0.3004, 0.0664],\n",
      "        [0.0843, 0.0535, 0.0382, 0.0163, 0.1518, 0.0599, 0.5618, 0.0343],\n",
      "        [0.1641, 0.0758, 0.1867, 0.0795, 0.1304, 0.0827, 0.0964, 0.1845],\n",
      "        [0.0702, 0.0550, 0.0537, 0.0211, 0.1374, 0.0384, 0.5920, 0.0321],\n",
      "        [0.1832, 0.1174, 0.1666, 0.1072, 0.1499, 0.0701, 0.0933, 0.1122],\n",
      "        [0.1310, 0.0804, 0.1026, 0.0504, 0.2226, 0.1058, 0.2116, 0.0955],\n",
      "        [0.1421, 0.1141, 0.1306, 0.0693, 0.1696, 0.1221, 0.1957, 0.0565],\n",
      "        [0.1101, 0.0835, 0.0756, 0.0382, 0.2475, 0.1039, 0.2638, 0.0775],\n",
      "        [0.1168, 0.0722, 0.0873, 0.0398, 0.1852, 0.0754, 0.3629, 0.0603],\n",
      "        [0.1755, 0.0780, 0.1724, 0.0722, 0.1529, 0.0768, 0.1721, 0.0999],\n",
      "        [0.1160, 0.0763, 0.1074, 0.0405, 0.1735, 0.1094, 0.2845, 0.0924],\n",
      "        [0.1552, 0.0798, 0.2886, 0.0999, 0.1345, 0.0786, 0.0790, 0.0845],\n",
      "        [0.1860, 0.0903, 0.1190, 0.0906, 0.2272, 0.1539, 0.0628, 0.0701],\n",
      "        [0.1626, 0.0695, 0.2075, 0.0967, 0.1356, 0.0713, 0.1288, 0.1280],\n",
      "        [0.1528, 0.1096, 0.1277, 0.0834, 0.2133, 0.1418, 0.0893, 0.0821],\n",
      "        [0.1535, 0.0682, 0.1625, 0.0768, 0.1668, 0.1141, 0.1170, 0.1412],\n",
      "        [0.1464, 0.0915, 0.1787, 0.0863, 0.1361, 0.0621, 0.1831, 0.1159],\n",
      "        [0.1561, 0.0586, 0.0852, 0.0395, 0.1978, 0.1154, 0.2488, 0.0985],\n",
      "        [0.1250, 0.0579, 0.1115, 0.0393, 0.1824, 0.0678, 0.3500, 0.0661],\n",
      "        [0.1977, 0.0598, 0.1235, 0.0606, 0.1563, 0.1339, 0.1256, 0.1426],\n",
      "        [0.1652, 0.0789, 0.2791, 0.0911, 0.1161, 0.0599, 0.1381, 0.0718],\n",
      "        [0.1070, 0.0853, 0.0711, 0.0343, 0.2262, 0.1045, 0.3200, 0.0517],\n",
      "        [0.1152, 0.0654, 0.0986, 0.0386, 0.2783, 0.0736, 0.2653, 0.0651],\n",
      "        [0.1926, 0.0983, 0.2290, 0.0863, 0.1250, 0.0710, 0.1200, 0.0779],\n",
      "        [0.1292, 0.0663, 0.1288, 0.0485, 0.1739, 0.0695, 0.2821, 0.1017],\n",
      "        [0.1018, 0.0598, 0.0901, 0.0371, 0.1712, 0.0490, 0.4398, 0.0511],\n",
      "        [0.1576, 0.0949, 0.0721, 0.0370, 0.2375, 0.1342, 0.2142, 0.0524],\n",
      "        [0.1667, 0.0976, 0.1683, 0.1011, 0.1818, 0.0713, 0.1019, 0.1112],\n",
      "        [0.1924, 0.0617, 0.2014, 0.0730, 0.1378, 0.1074, 0.0871, 0.1391]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1582, 0.0649, 0.1079, 0.0514, 0.2055, 0.1025, 0.2000, 0.1096],\n",
      "        [0.1528, 0.0794, 0.1330, 0.0649, 0.1754, 0.0910, 0.1604, 0.1430],\n",
      "        [0.1187, 0.0974, 0.2238, 0.1198, 0.1539, 0.1186, 0.0688, 0.0990],\n",
      "        [0.1209, 0.0851, 0.2428, 0.1282, 0.1259, 0.1113, 0.0547, 0.1311],\n",
      "        [0.1370, 0.1024, 0.2974, 0.1293, 0.1000, 0.0950, 0.0539, 0.0850],\n",
      "        [0.1979, 0.0940, 0.1598, 0.0979, 0.1199, 0.1736, 0.0444, 0.1125],\n",
      "        [0.1524, 0.0864, 0.2097, 0.1099, 0.1160, 0.1243, 0.1022, 0.0990],\n",
      "        [0.2048, 0.0625, 0.2309, 0.1002, 0.1368, 0.0970, 0.0636, 0.1041],\n",
      "        [0.1544, 0.1023, 0.0783, 0.0631, 0.1950, 0.1944, 0.1356, 0.0769],\n",
      "        [0.1640, 0.0702, 0.2000, 0.0479, 0.1563, 0.0839, 0.2310, 0.0467],\n",
      "        [0.1875, 0.1031, 0.1358, 0.0919, 0.1165, 0.2063, 0.0570, 0.1019],\n",
      "        [0.1675, 0.1034, 0.0896, 0.0727, 0.1807, 0.1603, 0.1458, 0.0800],\n",
      "        [0.1897, 0.0860, 0.1245, 0.0682, 0.1643, 0.1776, 0.1013, 0.0883],\n",
      "        [0.1582, 0.0955, 0.1439, 0.0923, 0.1216, 0.2009, 0.0719, 0.1157],\n",
      "        [0.1450, 0.0709, 0.2469, 0.1201, 0.1023, 0.1173, 0.0558, 0.1418],\n",
      "        [0.1679, 0.0650, 0.2122, 0.0928, 0.1216, 0.1317, 0.0570, 0.1518],\n",
      "        [0.1449, 0.0841, 0.3239, 0.1203, 0.0804, 0.0982, 0.0571, 0.0911],\n",
      "        [0.1524, 0.0749, 0.3231, 0.1118, 0.0884, 0.0864, 0.0450, 0.1179],\n",
      "        [0.1458, 0.0811, 0.3620, 0.1342, 0.0680, 0.0572, 0.0489, 0.1028],\n",
      "        [0.1806, 0.1057, 0.1224, 0.0783, 0.1437, 0.2164, 0.0676, 0.0853],\n",
      "        [0.1844, 0.0730, 0.1591, 0.1085, 0.1165, 0.1582, 0.0614, 0.1388],\n",
      "        [0.1746, 0.1111, 0.0750, 0.0516, 0.2087, 0.1954, 0.1192, 0.0643],\n",
      "        [0.1528, 0.0688, 0.1520, 0.0841, 0.1145, 0.2040, 0.0746, 0.1492],\n",
      "        [0.1545, 0.0773, 0.1320, 0.0836, 0.1137, 0.2166, 0.0552, 0.1671],\n",
      "        [0.2086, 0.0781, 0.1724, 0.0842, 0.1176, 0.1522, 0.0623, 0.1246],\n",
      "        [0.1997, 0.0885, 0.1367, 0.0753, 0.1559, 0.1301, 0.1207, 0.0932],\n",
      "        [0.1923, 0.0718, 0.2495, 0.1370, 0.0942, 0.0794, 0.0403, 0.1355],\n",
      "        [0.1718, 0.1194, 0.1025, 0.0975, 0.1701, 0.2118, 0.0528, 0.0742],\n",
      "        [0.1877, 0.0744, 0.0918, 0.0402, 0.1469, 0.0915, 0.2848, 0.0827],\n",
      "        [0.1906, 0.1085, 0.1438, 0.0886, 0.1150, 0.1941, 0.0570, 0.1024],\n",
      "        [0.1963, 0.0953, 0.0950, 0.0708, 0.1422, 0.2262, 0.0558, 0.1184],\n",
      "        [0.1890, 0.1017, 0.1380, 0.0747, 0.1390, 0.1856, 0.0532, 0.1186]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.1745, 0.1191, 0.1447, 0.0779, 0.1334, 0.2167, 0.0503, 0.0834],\n",
      "        [0.1625, 0.0835, 0.1295, 0.0833, 0.1444, 0.1567, 0.1166, 0.1234],\n",
      "        [0.2017, 0.0780, 0.1404, 0.0575, 0.1795, 0.1436, 0.1213, 0.0779],\n",
      "        [0.0950, 0.0414, 0.0677, 0.0240, 0.1479, 0.0454, 0.5336, 0.0449],\n",
      "        [0.1060, 0.0679, 0.0841, 0.0331, 0.1596, 0.0643, 0.4208, 0.0642],\n",
      "        [0.0911, 0.0447, 0.0672, 0.0243, 0.1495, 0.0504, 0.5118, 0.0609],\n",
      "        [0.1146, 0.1029, 0.1544, 0.0810, 0.1420, 0.0736, 0.1907, 0.1408],\n",
      "        [0.0804, 0.0421, 0.0655, 0.0291, 0.1492, 0.0509, 0.5327, 0.0501],\n",
      "        [0.0616, 0.0412, 0.0358, 0.0115, 0.1188, 0.0287, 0.6780, 0.0244],\n",
      "        [0.0740, 0.0333, 0.0411, 0.0136, 0.1080, 0.0385, 0.6655, 0.0261],\n",
      "        [0.1662, 0.0779, 0.1597, 0.0729, 0.1367, 0.0905, 0.1909, 0.1055],\n",
      "        [0.1423, 0.0764, 0.1877, 0.0775, 0.1623, 0.0726, 0.2007, 0.0805],\n",
      "        [0.1079, 0.0541, 0.1310, 0.0414, 0.1774, 0.0623, 0.3304, 0.0954],\n",
      "        [0.1939, 0.0620, 0.2578, 0.0951, 0.1384, 0.0623, 0.0929, 0.0975],\n",
      "        [0.0750, 0.0408, 0.0483, 0.0152, 0.1318, 0.0314, 0.6336, 0.0240],\n",
      "        [0.0933, 0.0490, 0.0729, 0.0287, 0.1545, 0.0506, 0.4822, 0.0687],\n",
      "        [0.1193, 0.0583, 0.1068, 0.0310, 0.1775, 0.0789, 0.3692, 0.0589],\n",
      "        [0.0682, 0.0344, 0.0505, 0.0145, 0.1142, 0.0310, 0.6605, 0.0267],\n",
      "        [0.0694, 0.0411, 0.0328, 0.0115, 0.1084, 0.0375, 0.6759, 0.0234],\n",
      "        [0.1753, 0.0715, 0.1987, 0.0886, 0.1237, 0.0813, 0.1102, 0.1507],\n",
      "        [0.0830, 0.0487, 0.0998, 0.0365, 0.1559, 0.0561, 0.4735, 0.0465],\n",
      "        [0.1032, 0.0644, 0.0741, 0.0319, 0.1777, 0.0726, 0.4237, 0.0524],\n",
      "        [0.1275, 0.0707, 0.1238, 0.0415, 0.2100, 0.0784, 0.3062, 0.0419],\n",
      "        [0.1416, 0.0572, 0.1769, 0.0615, 0.1740, 0.0721, 0.2285, 0.0881],\n",
      "        [0.0783, 0.0477, 0.0692, 0.0253, 0.1424, 0.0500, 0.5380, 0.0491],\n",
      "        [0.1398, 0.0468, 0.0849, 0.0304, 0.1946, 0.0630, 0.3722, 0.0682],\n",
      "        [0.1338, 0.0711, 0.0849, 0.0320, 0.2170, 0.0849, 0.3291, 0.0471],\n",
      "        [0.1189, 0.0696, 0.1178, 0.0449, 0.1702, 0.0922, 0.3115, 0.0748],\n",
      "        [0.1514, 0.0545, 0.1646, 0.0599, 0.1853, 0.0739, 0.2218, 0.0886],\n",
      "        [0.1213, 0.1027, 0.2215, 0.1115, 0.1062, 0.0686, 0.1239, 0.1444],\n",
      "        [0.0999, 0.0494, 0.1074, 0.0339, 0.1854, 0.0496, 0.4176, 0.0568],\n",
      "        [0.1201, 0.0566, 0.1141, 0.0370, 0.1989, 0.0559, 0.3483, 0.0691]],\n",
      "       device='cuda:0')\n",
      "predicted_labels:  tensor([[0.0983, 0.0587, 0.1214, 0.0430, 0.1870, 0.0661, 0.3389, 0.0866],\n",
      "        [0.0517, 0.0394, 0.0374, 0.0118, 0.1195, 0.0328, 0.6859, 0.0215],\n",
      "        [0.1373, 0.1042, 0.3397, 0.1266, 0.0780, 0.0801, 0.0680, 0.0662],\n",
      "        [0.1303, 0.0858, 0.3460, 0.1276, 0.0849, 0.0787, 0.0610, 0.0858],\n",
      "        [0.1850, 0.0774, 0.1209, 0.0798, 0.1995, 0.1568, 0.1039, 0.0768],\n",
      "        [0.1353, 0.1036, 0.1249, 0.0732, 0.1707, 0.0902, 0.1571, 0.1450],\n",
      "        [0.1541, 0.0842, 0.2887, 0.1078, 0.0901, 0.0733, 0.0740, 0.1279],\n",
      "        [0.1009, 0.0573, 0.0818, 0.0309, 0.1863, 0.0595, 0.4324, 0.0508],\n",
      "        [0.1170, 0.0530, 0.1498, 0.0613, 0.1896, 0.0669, 0.2300, 0.1323],\n",
      "        [0.1864, 0.0691, 0.3150, 0.1073, 0.0997, 0.0847, 0.0555, 0.0823],\n",
      "        [0.1565, 0.1006, 0.0762, 0.0466, 0.2028, 0.1537, 0.1999, 0.0637],\n",
      "        [0.1830, 0.0722, 0.2153, 0.0968, 0.1338, 0.0886, 0.0993, 0.1109],\n",
      "        [0.1524, 0.0681, 0.1256, 0.0474, 0.1858, 0.0631, 0.3063, 0.0513],\n",
      "        [0.1227, 0.0740, 0.1012, 0.0426, 0.2270, 0.0712, 0.3060, 0.0552],\n",
      "        [0.0944, 0.0916, 0.1260, 0.0850, 0.1293, 0.0921, 0.3104, 0.0712],\n",
      "        [0.1578, 0.0692, 0.1125, 0.0480, 0.1953, 0.1073, 0.2507, 0.0592],\n",
      "        [0.2129, 0.0629, 0.2991, 0.0987, 0.1038, 0.0718, 0.0624, 0.0885],\n",
      "        [0.1689, 0.0806, 0.1610, 0.0702, 0.2020, 0.1069, 0.1406, 0.0698],\n",
      "        [0.1326, 0.0936, 0.0974, 0.0429, 0.2238, 0.1350, 0.1936, 0.0810],\n",
      "        [0.1651, 0.1158, 0.1458, 0.0895, 0.1508, 0.1392, 0.0947, 0.0991],\n",
      "        [0.1075, 0.0619, 0.0884, 0.0279, 0.1861, 0.0623, 0.4144, 0.0515],\n",
      "        [0.1622, 0.0680, 0.1864, 0.0999, 0.1061, 0.1082, 0.0889, 0.1801],\n",
      "        [0.1542, 0.0803, 0.1867, 0.1006, 0.1164, 0.1139, 0.1158, 0.1323],\n",
      "        [0.1826, 0.0826, 0.3239, 0.1097, 0.0914, 0.0664, 0.0722, 0.0711],\n",
      "        [0.1866, 0.0621, 0.1893, 0.0923, 0.1258, 0.0683, 0.1191, 0.1566],\n",
      "        [0.1622, 0.0612, 0.1957, 0.0885, 0.1153, 0.1550, 0.0611, 0.1610],\n",
      "        [0.1590, 0.0656, 0.3073, 0.0959, 0.1194, 0.0565, 0.0730, 0.1233],\n",
      "        [0.1534, 0.0794, 0.1916, 0.0966, 0.1216, 0.1052, 0.0942, 0.1580],\n",
      "        [0.0975, 0.0707, 0.0573, 0.0288, 0.1326, 0.0808, 0.4858, 0.0464],\n",
      "        [0.1275, 0.0705, 0.1070, 0.0402, 0.1841, 0.1123, 0.2919, 0.0666],\n",
      "        [0.1805, 0.0549, 0.1098, 0.0586, 0.1385, 0.1236, 0.2069, 0.1271],\n",
      "        [0.1086, 0.0663, 0.1224, 0.0448, 0.1981, 0.0659, 0.3336, 0.0602]],\n",
      "       device='cuda:0')\n",
      "Test accuracy: 32.42188%\n"
     ]
    }
   ],
   "source": [
    "if(option == 1):\n",
    "    # Test the model on new data\n",
    "    test_dataset = MaqamDataset(mode='test', cache_file='1.pkl')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            # print(\"targets: \",targets)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs)\n",
    "            # Convert the list to a tensor (if it's not already a tensor)\n",
    "            probs_tensor = torch.tensor(outputs[1])\n",
    "\n",
    "            # Find the index of the class with the highest probability\n",
    "            predicted_label_index = torch.argmax(probs_tensor)\n",
    "            # print(\"outputs: \",predicted_label_index)\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            # print(\"predicted_labels: \",outputs)\n",
    "            total_correct += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "\n",
    "        test_acc = 100 * float(total_correct) / total_samples\n",
    "\n",
    "    print(f'Test accuracy: {test_acc:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: Train Loss=2.07646, Train Accuracy=15.49708%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 validation: val_loss=2.07148, val_acc=24.90272%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: Train Loss=2.06403, Train Accuracy=19.39571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 validation: val_loss=2.05810, val_acc=22.17899%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: Train Loss=2.03700, Train Accuracy=21.83236%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 validation: val_loss=2.04232, val_acc=24.12451%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: Train Loss=2.01498, Train Accuracy=25.53606%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 validation: val_loss=2.02520, val_acc=24.90272%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: Train Loss=1.98382, Train Accuracy=28.16764%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 validation: val_loss=2.01273, val_acc=23.73541%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: Train Loss=1.96797, Train Accuracy=30.21442%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 validation: val_loss=2.00817, val_acc=23.73541%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: Train Loss=1.94111, Train Accuracy=34.21053%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 validation: val_loss=1.99604, val_acc=26.45914%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: Train Loss=1.91074, Train Accuracy=39.37622%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 validation: val_loss=1.98016, val_acc=28.01556%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: Train Loss=1.88328, Train Accuracy=42.59259%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 validation: val_loss=1.96871, val_acc=30.73930%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: Train Loss=1.86521, Train Accuracy=46.19883%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 validation: val_loss=1.95985, val_acc=29.18288%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: Train Loss=1.82260, Train Accuracy=50.68226%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 validation: val_loss=1.94263, val_acc=32.68482%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: Train Loss=1.78053, Train Accuracy=53.60624%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 validation: val_loss=1.93821, val_acc=33.46304%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: Train Loss=1.75094, Train Accuracy=56.43275%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 validation: val_loss=1.92982, val_acc=35.01946%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: Train Loss=1.73468, Train Accuracy=59.84405%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40 validation: val_loss=1.91473, val_acc=38.52140%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: Train Loss=1.71113, Train Accuracy=60.52632%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40 validation: val_loss=1.93054, val_acc=33.46304%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: Train Loss=1.71294, Train Accuracy=60.23392%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40 validation: val_loss=1.92102, val_acc=35.79767%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: Train Loss=1.68773, Train Accuracy=62.76803%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40 validation: val_loss=1.92038, val_acc=36.18677%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: Train Loss=1.67958, Train Accuracy=64.13255%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40 validation: val_loss=1.91472, val_acc=36.18677%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: Train Loss=1.65054, Train Accuracy=68.03119%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40 validation: val_loss=1.89509, val_acc=37.35409%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: Train Loss=1.61715, Train Accuracy=71.24756%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40 validation: val_loss=1.89732, val_acc=37.35409%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: Train Loss=1.61540, Train Accuracy=71.73489%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40 validation: val_loss=1.90351, val_acc=36.57588%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: Train Loss=1.62443, Train Accuracy=70.27290%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40 validation: val_loss=1.90292, val_acc=36.18677%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40: Train Loss=1.59850, Train Accuracy=70.17544%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40 validation: val_loss=1.89804, val_acc=35.40856%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40: Train Loss=1.56488, Train Accuracy=75.04873%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40 validation: val_loss=1.90165, val_acc=35.79767%\n",
      "Early stopping. No improvement in validation loss for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.75000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "if(option == 2):\n",
    "    # Rest of the model definition and data loaders\n",
    "\n",
    "    # Initialize model and define loss function and optimizer\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = MFCC_LSTM().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for a specified number of epochs\n",
    "    num_epochs = 40\n",
    "    patience = 5  # Number of epochs to wait for improvement before early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "    no_improvement_epochs = 0\n",
    "\n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode for the current epoch\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, data in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "            inputs, targets = data  # MFCCs and labels\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the loss and accuracy metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "\n",
    "        # Calculate and print average loss and accuracy for the current epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = 100 * correct_predictions / total_samples\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss={avg_loss:.5f}, Train Accuracy={avg_accuracy:.5f}%')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(val_loader, desc='Validation', leave=False):\n",
    "                inputs, targets = data  # MFCCs and labels\n",
    "                targets = targets.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * len(targets)\n",
    "\n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                total_correct += (predicted_labels == targets).sum().item()\n",
    "                total_samples += len(targets)\n",
    "\n",
    "        val_loss /= len(val_dataset)\n",
    "        val_acc = 100 * total_correct / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} validation: val_loss={val_loss:.5f}, val_acc={val_acc:.5f}%')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(\"Early stopping. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "\n",
    "    # Load the best model state dict\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "    # Test the model on the test dataset\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            total_correct += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "\n",
    "    test_acc = 100 * total_correct / total_samples\n",
    "    print(f'Test Accuracy: {test_acc:.5f}%')\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'readerstest.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
