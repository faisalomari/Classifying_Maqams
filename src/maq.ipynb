{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import models.MaqamCNN1D\n",
    "import models.MaqamCNN2D\n",
    "import models.CNN_LSTM\n",
    "import models.MFCC_LSTM\n",
    "import models.MFCC_LSTM1D\n",
    "import models.ANNModel\n",
    "import models.ANNModel1\n",
    "import models.ANNModel2\n",
    "import MaqamDataset\n",
    "from MaqamDataset import*\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the code you should change the dataset path accordingly in the MaqamDataset.py code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters, batching size, and the option to chose the model you want to use.\n",
    "batch_size = 64\n",
    "option = 1 #       1-CNN                    2-LSTM                      3-ANN               4-combined_3models (just for test)\n",
    "if option==3:\n",
    "    feature = 'mfcc'\n",
    "elif option==1 or option==2:\n",
    "    feature = 'mfcc'\n",
    "# feature = 'chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the option is to use CNN model \n",
    "if option == 1:\n",
    "    # Load train and validation datasets\n",
    "    train_dataset = MaqamDataset(mode='train', cache_file='running_cache/train.pkl', feature=feature)\n",
    "    val_dataset = MaqamDataset(mode='val', cache_file='running_cache/validation.pkl', feature=feature)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    \n",
    "    l = 0.001  # Learning rate\n",
    "    \n",
    "    # Lists to store accuracy and loss values\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    print(\"__________________________________________________________________________________________________________________\")\n",
    "    print(\"Learning rate =\", l)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MaqamCNN2D().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "    \n",
    "    # Train the model for a specified number of epochs\n",
    "    num_epochs = 40\n",
    "    patience = num_epochs\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "    no_improvement_epochs = 0\n",
    "    \n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode for the current epoch\n",
    "        model.train()\n",
    "        \n",
    "        # Training loop\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        for i, data in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update loss and accuracy metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "        \n",
    "        # Calculate and print average loss and accuracy\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = 100 * correct_predictions / total_samples\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss={avg_loss:.5f}, Train Accuracy={avg_accuracy:.5f}%')\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(val_loader, desc='Validation', leave=False):\n",
    "                inputs, targets = data\n",
    "                targets = targets.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * len(targets)\n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                total_correct += (predicted_labels == targets).sum().item()\n",
    "                total_samples += len(targets)\n",
    "        val_loss /= len(val_dataset)\n",
    "        val_acc = 100 * total_correct / total_samples\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(avg_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} validation: val_loss={val_loss:.5f}, val_acc={val_acc:.5f}%')\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(\"Early stopping. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "    \n",
    "    # Load the best model state dict\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    # Test the model on the test dataset\n",
    "    test_dataset = MaqamDataset(mode='test', cache_file='running_cache/test.pkl', feature=feature)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            total_correct += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "    test_acc = 100 * total_correct / total_samples\n",
    "    print(f'Test Accuracy: {test_acc:.5f}%')\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'results/CNN1.pth')\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/CNN loss_plot.png')\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/CNN accuracy_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the option is to use LSTM model\n",
    "if option == 2:\n",
    "    l = 0.001  # Learning rate\n",
    "    \n",
    "    # Lists to store accuracy and loss values\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Load train and validation datasets\n",
    "    train_dataset = MaqamDataset(mode='train', cache_file='running_cache/train.pkl', feature=feature)\n",
    "    val_dataset = MaqamDataset(mode='val', cache_file='running_cache/val.pkl', feature=feature)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "    \n",
    "    print(\"_________________________________________________________\")\n",
    "    print(\"Learning rate =\", l)\n",
    "    \n",
    "    # Initialize model and define loss function and optimizer\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MFCC_LSTM1D().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "    \n",
    "    # Train the model for a specified number of epochs\n",
    "    num_epochs = 800\n",
    "    patience = num_epochs  # Number of epochs to wait for improvement before early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "    no_improvement_epochs = 0\n",
    "    \n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode for the current epoch\n",
    "        model.train()\n",
    "        \n",
    "        # Training loop\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, data in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update loss and accuracy metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "        \n",
    "        # Calculate and print average loss and accuracy for the current epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = 100 * correct_predictions / total_samples\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss={avg_loss:.5f}, Train Accuracy={avg_accuracy:.5f}%')\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(val_loader, desc='Validation', leave=False):\n",
    "                inputs, targets = data\n",
    "                targets = targets.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * len(targets)\n",
    "                \n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                total_correct += (predicted_labels == targets).sum().item()\n",
    "                total_samples += len(targets)\n",
    "        \n",
    "        val_loss /= len(val_dataset)\n",
    "        val_acc = 100 * total_correct / total_samples\n",
    "        \n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(avg_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} validation: val_loss={val_loss:.5f}, val_acc={val_acc:.5f}%')\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "        \n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(\"Early stopping. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "    \n",
    "    # Load the best model state dict\n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    # Test the model on the test dataset\n",
    "    test_dataset = MaqamDataset(mode='test', cache_file='running_cache/test.pkl', feature=feature)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "    \n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            total_correct += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "    \n",
    "    test_acc = 100 * total_correct / total_samples\n",
    "    print(f'Test Accuracy: {test_acc:.5f}%')\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'results/lstm.pth')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/LSTM loss_plot_lr_{l}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/LSTM accuracy_plot_lr_{l}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SummaryWriter for logging\n",
    "writer = SummaryWriter('logs/')\n",
    "\n",
    "# If the option is to use ANN model\n",
    "if option == 3:\n",
    "    l = 0.0001  # Learning rate\n",
    "    \n",
    "    # Lists to store accuracy and loss values\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Load train and validation datasets\n",
    "    train_dataset = MaqamDataset(mode='train', cache_file='running_cache/train.pkl', feature=feature)\n",
    "    val_dataset = MaqamDataset(mode='val', cache_file='running_cache/val.pkl', feature=feature)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    \n",
    "    print(\"_________________________________________________________\")\n",
    "    print(\"Learning rate =\", l)\n",
    "    \n",
    "    # Initialize model and define loss function and optimizer\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ANNModel2().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "    \n",
    "    num_epochs = 125\n",
    "    patience = num_epochs\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state_dict = None\n",
    "    no_improvement_epochs = 0\n",
    "    \n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Log learning rate for the current epoch\n",
    "        writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        for i, data in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_accuracy = 100 * correct_predictions / total_samples\n",
    "        train_losses.append(avg_loss)\n",
    "        train_accuracies.append(avg_accuracy)\n",
    "        \n",
    "        # Log training loss and accuracy\n",
    "        writer.add_scalar('Train Loss', avg_loss, epoch)\n",
    "        writer.add_scalar('Train Accuracy', avg_accuracy, epoch)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}: Train Loss={avg_loss:.5f}, Train Accuracy={avg_accuracy:.5f}%')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(val_loader, desc='Validation', leave=False):\n",
    "                inputs, targets = data\n",
    "                targets = targets.to(device)\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * len(targets)\n",
    "                \n",
    "                _, predicted_labels = torch.max(outputs, 1)\n",
    "                total_correct += (predicted_labels == targets).sum().item()\n",
    "                total_samples += len(targets)\n",
    "        \n",
    "        val_loss /= len(val_dataset)\n",
    "        val_acc = 100 * total_correct / total_samples\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} validation: val_loss={val_loss:.5f}, val_acc={val_acc:.5f}%')\n",
    "        \n",
    "        # Log validation loss and accuracy\n",
    "        writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "        writer.add_scalar('Validation Accuracy', val_acc, epoch)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state_dict = model.state_dict()\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "        \n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(\"Early stopping. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "        \n",
    "        # Log histograms of model parameters\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param, epoch)\n",
    "            \n",
    "    if best_model_state_dict is not None:\n",
    "        model.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    # Test the model on the test dataset\n",
    "    test_dataset = MaqamDataset(mode='test', cache_file='running_cache/test.pkl', feature=feature)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "    \n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing', leave=False):\n",
    "            inputs, targets = data\n",
    "            targets = targets.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            total_correct += (predicted_labels == targets).sum().item()\n",
    "            total_samples += len(targets)\n",
    "    \n",
    "    test_acc = 100 * total_correct / total_samples\n",
    "    print(f'Test Accuracy: {test_acc:.5f}%')\n",
    "    writer.close()\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), 'results/ANN.pth')\n",
    "    \n",
    "    # Plot and save loss and accuracy curves\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/ANN loss_plot_lr_{l}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'Learning Rate: {l}')\n",
    "    plt.savefig(f'results/ANN accuracy_plot_lr_{l}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_dataset = MaqamDataset(mode='test', cache_file='running_cache/test2.pkl', feature=feature)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Lists to store accuracy by maqam statistics\n",
    "acc_by_maqam_idx = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "acc_by_maqam_ss = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "acc_by_maqam_cc = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "p = []  # List to store predicted labels\n",
    "t = []  # List to store true labels\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        inputs, targets = data\n",
    "        targets = targets.to(device)\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        t += targets\n",
    "        p += predicted_labels\n",
    "        total_correct += (predicted_labels == targets).sum().item()\n",
    "        total_samples += len(targets)\n",
    "        \n",
    "        # Calculate accuracy by maqam statistics\n",
    "        for i in acc_by_maqam_idx:\n",
    "            ss = 0\n",
    "            cc = 0\n",
    "            a = [-1 if x != i else i for x in targets]\n",
    "            for counter in range(len(a)):\n",
    "                if a[counter] != -1:\n",
    "                    ss += 1\n",
    "                    if a[counter] == predicted_labels[counter]:\n",
    "                        cc += 1\n",
    "            acc_by_maqam_ss[i] += ss\n",
    "            acc_by_maqam_cc[i] += cc\n",
    "\n",
    "# Calculate overall test accuracy\n",
    "test_acc = 100 * total_correct / total_samples\n",
    "print(f'Test Accuracy: {test_acc:.5f}%')\n",
    "\n",
    "# Define maqam classes\n",
    "classes = ['Ajam', 'Bayat', 'Hijaz', 'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "\n",
    "# Print accuracy by maqam\n",
    "print(f'Accuracy by maqam:')\n",
    "for i in range(8):\n",
    "    print(classes[i] + \" accuracy = \", acc_by_maqam_cc[i] / acc_by_maqam_ss[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "combined_tensor = torch.stack(t)\n",
    "combined_tensor1 = torch.stack(p)\n",
    "true = combined_tensor.cpu()\n",
    "predicted = combined_tensor1.cpu()\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true, predicted)\n",
    "\n",
    "# Create a pandas DataFrame to display the confusion matrix with class names\n",
    "class_names = ['Ajam', 'Bayat', 'Hijaz',\n",
    "                'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix using seaborn heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Save the confusion matrix plot as a PNG image\n",
    "plt.savefig('results/confusion_matrix.jpeg', format='jpeg')\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()\n",
    "\n",
    "# Save the confusion matrix to a CSV file\n",
    "cm_df.to_csv('results/confusion_matrix.csv')\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true, predicted)\n",
    "\n",
    "# Calculate the probability representation of the confusion matrix\n",
    "cm_probability = cm / cm.sum()\n",
    "\n",
    "# Create a pandas DataFrame to display the confusion matrix with class names\n",
    "class_names = ['Ajam', 'Bayat', 'Hijaz',\n",
    "                'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "cm_df_probability = pd.DataFrame(\n",
    "    cm_probability, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix with probabilities using seaborn heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_df_probability, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix (Probability)')\n",
    "\n",
    "# Save the confusion matrix plot as a PNG image\n",
    "plt.savefig('results/confusion_matrix_probability.png', format='png')\n",
    "\n",
    "# Show the plot (optional)\n",
    "plt.show()\n",
    "print(\"Option2\")\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true, predicted)\n",
    "\n",
    "# Calculate the probability representation of the confusion matrix\n",
    "cm_probability = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a pandas DataFrame to display the confusion matrix with class names\n",
    "class_names = ['Ajam', 'Bayat', 'Hijaz', 'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "cm_df_probability = pd.DataFrame(cm_probability, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix with probabilities using seaborn heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_df_probability, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('True Class')\n",
    "plt.title('Confusion Matrix (Probability)')\n",
    "\n",
    "# Save the confusion matrix plot as a PNG image\n",
    "plt.savefig('results/confusion_matrix_probability.png', format='png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Convert the true labels and predicted labels to one-hot encoded format\n",
    "n_classes = len(np.unique(true))\n",
    "true_labels_onehot = label_binarize(true, classes=np.arange(n_classes))\n",
    "predicted_labels_onehot = label_binarize(predicted, classes=np.arange(n_classes))\n",
    "\n",
    "# Compute the ROC curve for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(true_labels_onehot[:, i], predicted_labels_onehot[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and AUC\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(true_labels_onehot.ravel(), predicted_labels_onehot.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curve for each class\n",
    "classes = ['Ajam', 'Bayat', 'Hijaz', 'Kurd', 'Nahawand', 'Rast', 'Saba', 'Seka']\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve ({classes[i]}) (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the micro-average ROC curve\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})', linestyle=':', linewidth=4)\n",
    "\n",
    "# Customize the plot\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Multiclass Classification')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('results/ROC_curve.png', format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if option == 4: #combine 3 models results\n",
    "    batch_size = 32\n",
    "\n",
    "    # Load the test dataset\n",
    "    test_dataset = MaqamDataset(mode='test', cache_file='test.pkl')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "    # Load models and their weights \n",
    "    model1 = ANNModel().to(device)\n",
    "    model2 = ANNModel1().to(device)\n",
    "    model3 = ANNModel2().to(device)\n",
    "\n",
    "    model1_path = \"results/85FullData/ANN.pth\"\n",
    "    model2_path = \"results/94mid_data/ANN.pth\"\n",
    "    model3_path = \"results/all_features_85/ANN.pth\"\n",
    "\n",
    "    model1.load_state_dict(torch.load(model1_path))\n",
    "    model2.load_state_dict(torch.load(model2_path))\n",
    "    model3.load_state_dict(torch.load(model3_path))\n",
    "\n",
    "    # Set the models to evaluation mode\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "\n",
    "    # Define the weights for combining the models\n",
    "    weight1 = 0.25\n",
    "    weight2 = 0.5\n",
    "    weight3 = 0.25\n",
    "\n",
    "    # Prepare lists to store the final predictions and corresponding labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Prepare lists to store the predictions and labels for each model independently\n",
    "    model1_predictions = []\n",
    "    model2_predictions = []\n",
    "    model3_predictions = []\n",
    "\n",
    "    # Loop through the test data\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)  # Move data to the device (GPU)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get the predictions from each model\n",
    "            predictions1 = model1(inputs)\n",
    "            predictions2 = model2(inputs)\n",
    "            predictions3 = model3(inputs)\n",
    "\n",
    "            # Save the predictions of each model for individual accuracy calculation\n",
    "            model1_predictions.extend(predictions1.argmax(dim=1).cpu().numpy())\n",
    "            model2_predictions.extend(predictions2.argmax(dim=1).cpu().numpy())\n",
    "            model3_predictions.extend(predictions3.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "            # Combine the predictions using the specified weights\n",
    "            combined_predictions = weight1 * predictions1 + weight2 * predictions2 + weight3 * predictions3\n",
    "\n",
    "            # Apply softmax to get the probabilities\n",
    "            probabilities = F.softmax(combined_predictions, dim=1)\n",
    "\n",
    "            # Get the class with the highest probability as the predicted class\n",
    "            _, predicted_labels = torch.max(probabilities, 1)\n",
    "\n",
    "            # Append the predictions and labels to the lists\n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())  # Convert back to CPU and extract the numpy array\n",
    "            all_labels.extend(labels.cpu().numpy())  # Convert back to CPU and extract the numpy array\n",
    "\n",
    "    # Calculate the accuracy of each model independently\n",
    "    correct_model1 = sum([1 for pred, true in zip(model1_predictions, all_labels) if pred == true])\n",
    "    correct_model2 = sum([1 for pred, true in zip(model2_predictions, all_labels) if pred == true])\n",
    "    correct_model3 = sum([1 for pred, true in zip(model3_predictions, all_labels) if pred == true])\n",
    "\n",
    "    total_samples = len(all_labels)\n",
    "    acc_model1 = correct_model1 / total_samples * 100\n",
    "    acc_model2 = correct_model2 / total_samples * 100\n",
    "    acc_model3 = correct_model3 / total_samples * 100\n",
    "\n",
    "    print(f'Model 1 Accuracy: {acc_model1:.5f}%')\n",
    "    print(f'Model 2 Accuracy: {acc_model2:.5f}%')\n",
    "    print(f'Model 3 Accuracy: {acc_model3:.5f}%')\n",
    "\n",
    "    # Calculate the combined accuracy\n",
    "    correct_combined = sum([1 for pred, true in zip(all_predictions, all_labels) if pred == true])\n",
    "    acc_combined = correct_combined / total_samples * 100\n",
    "    print(f'Combined Accuracy: {acc_combined:.5f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
